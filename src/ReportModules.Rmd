---
title: "Report Modules"
author: "Biomed 8"
date: "2025-06-01"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(CoxBoost)
library(dplyr)
library(GEOquery)
library(ggplot2)
library(glmnet)
library(limma)
library(randomForestSRC)
library(pec)
library(pROC)
library(prodlim)
library(RColorBrewer)
library(riskRegression)
library(reshape2)
library(survival)
library(survminer)
library(timeROC)
library(tidyr) 

set.seed(3888)

predictRisk.CoxBoost <- function(object, newdata, times, ...) {
  
  # make sure the covariate order is identical
  X <- as.matrix(newdata[, object$xnames, drop = FALSE])
  
  # linear predictor for the NEW data
  lp <- as.vector(predict(object, newdata = X, type = "lp"))
  
  # grab the baseline cumulative hazard that we stored in the model;
  # build a step function so we can evaluate it at arbitrary 'times'
  H0_step <- stats::stepfun(object$bh_time,
                            c(0, object$bh_hazard))
  
  H0_vec  <- H0_step(times)          # baseline cumul. haz. at all eval times
  
  # matrix:  nrow = n_obs,  ncol = length(times)
  surv_mat <- exp(-outer(exp(lp), H0_vec, "*"))
  
  risk_mat <- 1 - surv_mat           # Score() expects RISKS
  return(risk_mat)
}
```



```{r load_data}
# Extract useful data from GEO object
extract_gse_data <- function(gse) {
  list(
    featureData = fData(gse),
    phenoData = pData(gse),
    eMat = exprs(gse)
  )
}

# Robust GEO downloader
get_geo_data <- function(gse_id, destdir = tempdir(), retries = 5) {
  message(paste("[INFO]: Attempting to load", gse_id))
  for (i in 1:retries) {
    tryCatch({
      gse_list <- getGEO(gse_id, destdir = destdir, GSEMatrix = TRUE, AnnotGPL = FALSE)
      gse <- gse_list[[1]]
      return(gse)
    }, error = function(e) {
      message(paste("[INFO]: Attempt", i, "failed for", gse_id, ":", e$message))
      if (i < retries) Sys.sleep(3) else stop(paste("Failed to download", gse_id))
    })
  }
}

# --- Step 1: Load GEO datasets ---
download_dir <- file.path(getwd(), "GEO_data")
if (!dir.exists(download_dir)) dir.create(download_dir)

GSE28735 <- get_geo_data("GSE28735", destdir = download_dir) %>% extract_gse_data()
GSE62452 <- get_geo_data("GSE62452", destdir = download_dir) %>% extract_gse_data()

# --- Step 2: Clean phenotype data ---

pheno287 <- GSE28735$phenoData %>%
  mutate(
    is_dead = as.numeric(replace(`cancer_death:ch1`, `cancer_death:ch1` == "na", NA)),
    months_survived = as.numeric(replace(`survival_month:ch1`, `survival_month:ch1` == "na", NA))
  ) %>%
  filter(!grepl("non-tumor tissue", source_name_ch1) & !is.na(is_dead))

pheno624 <- GSE62452$phenoData %>%
  mutate(
    is_dead = as.numeric(replace(`survival status:ch1`, `survival status:ch1` %in% c("na","?"), NA)),
    months_survived = as.numeric(replace(`survival months:ch1`, `survival months:ch1` %in% c("na","?"), NA))
  ) %>%
  filter(grepl("Pancreatic tumor", `tissue:ch1`) & !is.na(is_dead))

# Combine phenotype
pheno <- bind_rows(pheno287, pheno624)

# --- Step 3: Combine expression data ---

common_genes <- intersect(rownames(GSE28735$eMat), rownames(GSE62452$eMat))
subset_eMat_GSE28735 <- GSE28735$eMat[common_genes, ]
subset_eMat_GSE62452 <- GSE62452$eMat[common_genes, ]
combined_matrix <- cbind(subset_eMat_GSE28735, subset_eMat_GSE62452)

# --- Step 4: Save validation samples and remove them from training data ---

selected_ids <- c("GSM1527137", "GSM1527230", "GSM711944", "GSM711984")

# Save selected samples to CSV
outdir <- file.path(getwd(), "patient_data")
if (!dir.exists(outdir)) dir.create(outdir)

for (sample_id in selected_ids) {
  expr_df <- data.frame(
    gene_id    = rownames(combined_matrix),
    expression = combined_matrix[, sample_id]
  )
  ph <- pheno[sample_id, ]
  expr_df$is_dead         <- ph$is_dead
  expr_df$months_survived <- ph$months_survived
  
  write.csv(expr_df, file = file.path(outdir, paste0(sample_id,"is_dead_", ph$is_dead, ".csv")),
            row.names = FALSE, quote = FALSE)
}

# Remove validation samples
pheno <- pheno[!rownames(pheno) %in% selected_ids, ]
combined_matrix <- combined_matrix[, colnames(combined_matrix) %in% rownames(pheno)]

# Final check
stopifnot(all(colnames(combined_matrix) == rownames(pheno)))

# Final object
gse <- list(
  featureData = GSE28735$featureData,
  phenoData = pheno,
  eMat = combined_matrix
)
```

```{r method_eda}
# Applying summary function across samples
summary_values_eda <- summary(as.vector(gse$eMat))
summary_per_sample_eda <- as.data.frame(t(apply(gse$eMat, 2, summary)))

# Set SampleID as a column (not using rownames to avoid duplication)
summary_per_sample_eda$SampleID <- rownames(summary_per_sample_eda)
rownames(summary_per_sample_eda) <- NULL  # Remove rownames to prevent duplication

summary_per_sample_eda <- summary_per_sample_eda %>%
  rename(
    Min = "Min.",
    Q1 = "1st Qu.",
    Median = "Median",
    Mean = "Mean",
    Q3 = "3rd Qu.",
    Max = "Max."
  ) %>%
  
  select(SampleID, Min, Q1, Median, Mean, Q3, Max)

summary_long_eda <- summary_per_sample_eda %>%
  pivot_longer(cols = c("Min", "Q1", "Median", "Mean", "Q3", "Max"), names_to = "Statistic", values_to = "Value")

# PCA Setup - using survival status instead of tissue
gse$phenoData$Survival_Status <- factor(
  ifelse(gse$phenoData$is_dead == 0, "Alive", "Deceased"),
  levels = c("Alive", "Deceased")
)

pca_all <- prcomp(t(gse$eMat), scale. = TRUE)

# Heatmap Data Preparation 
var_genes_eda <- apply(gse$eMat, 1, var)
top75_genes_eda <- names(sort(var_genes_eda, decreasing = TRUE)[1:75])
annotation_col_eda <- data.frame(Survival = gse$phenoData$Survival_Status)
rownames(annotation_col_eda) <- rownames(gse$phenoData)

# Prepare data for survival time distribution
prepare_survival_time_data <- function() {
  # Create a dataframe with survival time and status
  survival_data <- data.frame(
    SampleID = rownames(gse$phenoData),
    SurvivalTime = gse$phenoData$months_survived, 
    Status = factor(
      ifelse(gse$phenoData$is_dead == 0, "Alive", "Deceased"),
      levels = c("Alive", "Deceased")
    )
  )
  return(survival_data)
}

# Prepare data for volcano plot - differential expression between alive/deceased
prepare_volcano_data <- function() {
  # Create design matrix
  design <- model.matrix(~gse$phenoData$is_dead)
  colnames(design) <- c("Intercept", "Deceased_vs_Alive")
  
  # Fit linear model
  fit <- limma::lmFit(gse$eMat, design)
  fit <- limma::eBayes(fit)
  
  # Get results
  results <- limma::topTable(fit, coef = "Deceased_vs_Alive", number = Inf)
  
  # Add gene names
  results$GeneID <- rownames(results)
  
  # Flag significant genes (adjust threshold as needed)
  results$Significant <- ifelse(results$adj.P.Val < 0.05, "Yes", "No")
  results$Label <- ifelse(results$Significant == "Yes" & abs(results$logFC) > 1, results$GeneID, "")
  
  return(results)
}

survival_time_data <- prepare_survival_time_data()
volcano_data <- prepare_volcano_data()
```

```{r method_select_features}
# Construct survival object with survival time and event status
surv_obj <- with(gse$phenoData, Surv(as.numeric(months_survived), as.numeric(is_dead)))

# Prepare feature matrix
X <- t(gse$eMat) %>% as.matrix()
train_idx <- createDataPartition(factor(gse$phenoData$is_dead), p = 0.80, list = FALSE)

safe_names <- make.names(colnames(X), unique = TRUE)
colnames(X) <- safe_names
lookup <- data.frame(
  safe = safe_names,              # length 28869
  raw  = rownames(gse$eMat),      # length 28869
  stringsAsFactors = FALSE
)

# Split into training and testing sets
X_train <- X[train_idx, ]
X_test  <- X[-train_idx, ]

# Survival objects for training/testing sets
train_surv <- surv_obj[train_idx]
test_surv <- surv_obj[-train_idx]

# Create dataframes for training and testing
train_df <- data.frame(
  time    = as.numeric(gse$phenoData$months_survived[train_idx]),
  is_dead = as.numeric(gse$phenoData$is_dead[train_idx]),
  as.data.frame(X_train, check.names = FALSE)
)

test_df  <- data.frame(
  time    = as.numeric(gse$phenoData$months_survived[-train_idx]),
  is_dead = as.numeric(gse$phenoData$is_dead[-train_idx]),
  as.data.frame(X_test , check.names = FALSE)
)

# Run Random Survival Forest for feature selection
rsf_model <- rfsrc(Surv(time, is_dead) ~ ., data = train_df, 
                   ntree = 1000, 
                   importance = TRUE)

# Get variable importance by minimal depth
var_imp <- var.select(rsf_model, method = "md", verbose = FALSE)

top_by_md <- var_imp$md.obj$topvars          # may be character(0)

if (length(top_by_md) == 0) {                # fall-back: use VIMP
  vimp_sorted <- sort(rsf_model$importance,
                      decreasing = TRUE,
                      na.last   = TRUE)
  top_by_md <- names(vimp_sorted)
}

n_features_to_select <- 15
selected_features <- top_by_md[1:min(n_features_to_select,
                                     length(top_by_md))]
```

```{r method_build_model}

# Prepare data for CoxBoost with selected features only
X_train_selected <- X_train[, selected_features, drop = FALSE]
X_test_selected <- X_test[, selected_features, drop = FALSE]

# STANDARDIZATION STEP
X_train_selected_std <- scale(X_train_selected)
X_test_selected_std <- scale(X_test_selected, 
                             center = attr(X_train_selected_std, "scaled:center"),
                             scale = attr(X_train_selected_std, "scaled:scale"))

# Set up CoxBoost - note it requires time and status separately
train_time <- train_df$time
train_is_dead <- train_df$is_dead  
test_time <- test_df$time
test_is_dead <- test_df$is_dead    

# hyperparams from hptune.rmd chosen by min ibs score
penalty_val <- 15
stepsize <- 0.3


message("[INFO]: Calculating optimal boosting steps")
# Cross validate to find optimal number of boosting steps
cv_res <- cv.CoxBoost(
  time      = train_time,
  status    = train_is_dead,
  x         = X_train_selected_std,
  maxstepno = 100,
  K         = 10,
  penalty   = penalty_val,
  stepsize.factor = stepsize,
  unpen.index = NULL
)

# extract optimal steps
optimal_steps <- cv_res$optimal.step
message("[INFO]: Optimal boosting steps = ", optimal_steps)
message("[INFO]: Fitting model")
# Fit final CoxBoost model with the same penalty
coxboost_model <- CoxBoost(
  time      = train_time,
  status    = train_is_dead,
  x         = X_train_selected_std,
  stepno    = optimal_steps,
  stepsize.factor = stepsize,
  penalty   = penalty_val,
  unpen.index = NULL
)

# linear predictor for the training data
lp_train <- as.vector(
  predict(coxboost_model,
          newdata = X_train_selected_std,
          type    = "lp",
          at.step = optimal_steps)   # <- returns a vector
)

# data frame that will be fed to coxph()
df_train <- data.frame(
  time   = train_time,
  status = train_is_dead,
  lp     = lp_train       
)

# "null" Cox model 
coxph_base <- coxph(
  Surv(time, status) ~ offset(lp),   
  data   = df_train,
  method = "breslow"
)

bh <- basehaz(coxph_base, centered = FALSE)

coxboost_model$bh_time   <- bh$time
coxboost_model$bh_hazard <- bh$hazard
coxboost_model$stepno <- optimal_steps

# Predict on test set
risk_scores_test <- as.vector(
  predict(coxboost_model,
          newdata = X_test_selected_std,
          type    = "lp",
          at.step = optimal_steps)
)

# Split test data into high/low risk groups using median cutoff
risk_groups <- ifelse(risk_scores_test > median(risk_scores_test), "High", "Low")
risk_groups <- factor(risk_groups, levels = c("Low", "High"))

# Create actual status for comparison
actual_is_dead <- factor(
  ifelse(test_is_dead == 1, "High", "Low"),
  levels = c("Low", "High")
)

# Calculate C-index
c_index <- rcorr.cens(-risk_scores_test, Surv(test_time, test_is_dead))[1]

# Generate confusion matrix
cm_caret <- confusionMatrix(
  data = risk_groups,
  reference = actual_is_dead,
  positive = "High"
)
```

```{r results_km}
prepare_survival_data <- function() {
  data.frame(
    time = test_time,
    status = test_is_dead,
    risk_group = factor(risk_groups)
  )
}
km_data <- prepare_survival_data()
surv_fit <- survfit(Surv(time, status) ~ risk_group, data = km_data)
surv_diff <- survdiff(Surv(time, status) ~ risk_group, data = km_data)

p_val <- 1 - pchisq(surv_diff$chisq, df = length(surv_diff$n) - 1)
p_text <- ifelse(p_val < 0.001, "p < 0.001", paste("p =", round(p_val, 3)))

km_plot <- ggsurvplot(
  surv_fit, data = km_data,
  pval = p_text, risk.table = FALSE,
  palette = c("#2E9FDF", "#E7B800"),
  xlab = "Time (months)", ylab = "Survival Probability",
  title = "Survival by Predicted Risk Group",
  legend.labs = c("Low Risk", "High Risk"),
  legend.title = "Risk Group",
  ggtheme = theme_bw(), conf.int = TRUE,
  censor.shape = "+", censor.size = 4
)
ggsave("km_survival_plot.png", plot = km_plot$plot)

```

```{r results_time_auc}
# Prepare data for time-dependent AUC plot
prepare_time_auc_data <- function() {
  delta <- ifelse(test_is_dead == 1, 1, 0)
  T <- test_time
  marker <- risk_scores_test
  
  n_event <- sum(delta == 1)
  n_cens <- sum(delta == 0)
  if (n_event == 0 || n_cens == 0) return(NULL)
  
  eval_times2 <- seq(6, floor(max(T)), by = 6)
  eval_times2 <- eval_times2[sapply(eval_times2, function(t)
    any(delta == 1 & T <= t) && any(delta == 0 & T >= t))]
  if (length(eval_times2) < 2) return(NULL)
  
  td <- timeROC::timeROC(T, delta, as.numeric(marker), cause = 1,
                         times = eval_times2, iid = TRUE,
                         weighting = "marginal")
  
  auc_df <- data.frame(
    time = td$times,
    auc = td$AUC,
    se = td$inference$vect_sd_1
  )
  auc_df$lower <- pmax(auc_df$auc - 1.96 * auc_df$se, 0)
  auc_df$upper <- pmin(auc_df$auc + 1.96 * auc_df$se, 1)
  auc_df$eval_times <- eval_times2
  
  return(auc_df)
}

plot_data <- prepare_time_auc_data()

auc_plot <- ggplot(plot_data, aes(time, auc)) +
  geom_line(colour = "#2E9FDF", linewidth = 1) +
  geom_ribbon(aes(ymin = lower, ymax = upper), fill = "#2E9FDF", alpha = .2) +
  geom_hline(yintercept = .5, linetype = "dashed", colour = "grey50") +
  coord_cartesian(ylim = c(0, 1)) +
  scale_x_continuous(breaks = plot_data$eval_times) +
  theme_bw() +
  labs(title = "Time-dependent AUC (Test Set)",
       x = "Months Since Diagnosis", y = "AUC")
ggsave("AUC_plot.png", plot = auc_plot)

```

```{r results_brier}
# Helper function to calculate Brier score
calculate_brier_score <- function() {
  # Define evaluation times for Brier score
  eval_times <- seq(6, floor(max(test_time)), by = 6)
  eval_times <- eval_times[sapply(eval_times, function(t)
    any(test_is_dead == 1 & test_time <= t) && any(test_time >= t))]
  
  # Prepare test data for Score function
  test_score_df <- data.frame(
    time    = test_time,
    is_dead = test_is_dead,
    as.data.frame(X_test_selected_std)
  )
  
  # Calculate Brier score with error handling
  score_res <- tryCatch({
    riskRegression::Score(
      object       = list(CoxBoost = coxboost_model),
      formula      = Surv(time, is_dead) ~ 1,
      data         = test_score_df,
      times        = eval_times,
      metrics      = "brier",
      cens.model   = "km",
      split.method = "none",
      summary      = "ibs"
    )
  }, error = function(e) e)
  
  # Process results
  if (inherits(score_res, "error") || length(eval_times) < 2) {
    warning("Brier-score computation failed: ",
            if (inherits(score_res, "error")) score_res$message else "no eval times")
    brier_df  <- NULL
    ibs_value <- NA_real_
  } else {
    brier_df <- score_res$Brier$score[score_res$Brier$score$model == "CoxBoost", c("times", "Brier")]
    names(brier_df) <- c("time", "brier")
    ibs_value <- score_res$Brier$score[model == "CoxBoost" & times == max(times), IBS]
  }
  
  return(list(brier_df = brier_df, ibs_value = ibs_value, eval_times = eval_times))
}

brier_results <- calculate_brier_score()
brier_df <- brier_results$brier_df

brier_plot <- ggplot(brier_df, aes(time, brier)) +
  geom_line(colour = "#2E9FDF", linewidth = 1) +
  geom_hline(yintercept = .25, linetype = "dashed", colour = "grey60") +
  coord_cartesian(ylim = c(0, 1)) +
  scale_x_continuous(breaks = brier_df$time) +
  theme_bw() +
  labs(title = "Time-dependent Brier Score (Test Set)",
       x = "Months Since Diagnosis", y = "Brier Score")

```

```{r results_feature_importance}
extract_gene_symbol <- function(gene_assignment) {
  parts <- strsplit(gene_assignment, " // ")[[1]]
  if (length(parts) >= 2) return(trimws(parts[2])) else return(NA)
}

coefs <- coef(coxboost_model)[selected_features]

coef_df <- data.frame(
  feature = selected_features,
  coefficient = coefs,
  stringsAsFactors = FALSE
) %>%
  mutate(
    original_id = lookup$raw[match(feature, lookup$safe)],
    gene_info = GSE28735$featureData$gene_assignment[match(original_id, rownames(GSE28735$featureData))],
    gene_symbol = sapply(gene_info, extract_gene_symbol, USE.NAMES = FALSE),
    display_name = ifelse(!is.na(gene_symbol), 
                          paste0(gene_symbol, " (", feature, ")"), 
                          feature),
    impact = ifelse(coefficient > 0, "Risk (Worse Survival)", "Protective (Better Survival)"),
    abs_coef = abs(coefficient)
  ) %>%
  arrange(desc(abs_coef))

feat_imp <- ggplot(coef_df, aes(x = reorder(display_name, abs_coef), y = coefficient, fill = impact)) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = c("Protective (Better Survival)" = "#2E9FDF", 
                               "Risk (Worse Survival)" = "#E7B800")) +
  coord_flip() +
  labs(
    title = "Feature Importance in CoxBoost Survival Model",
    subtitle = "Top genes ranked by effect size",
    x = "", y = "Coefficient",
    fill = "Impact"
  ) +
  theme_bw() +
  theme(
    legend.position = "bottom",
    axis.text.y = element_text(size = 10),
    plot.title = element_text(size = 16, face = "bold"),
    plot.subtitle = element_text(size = 12)
  )
ggsave("feature_importance_coxboost.png", plot = feat_imp)

```