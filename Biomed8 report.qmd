---
title: "Biomed8 Group Report"
format: html
editor: visual
---

## Executive Summary

Improved prognostic tools are needed to guide the treatment of pancreatic cancer, which has one of the highest mortality rates in the world. (University of Utah Health, 2019) This project addresses this hurdle by using gene expression data to develop a personalised survival prediction tool for clinicians’ patients. Our approach utilises Gene Expression Omnibus datasets, which are publicly available, to identify biomarkers and develop a robust predictive model for pathologists.

Our main findings were the identification of select significant genes from an initial pool of over 28,000 genes using a minimum depth Random Forest. The selected genes were most predictive of survival in cancer patients. Subsequently, a CoxBoost model was trained and optimised on the selected features through hyperparameter tuning. Model performance was evaluated using an independent test set and measured primarily by the integrated Brier score (IBS). The concordance index, also known as the C-index and the time-dependent area under the ROC curve, was also used.

This analysis holds practical relevance in its potential to increase the efficiency of clinicians. It involves risk stratification by providing personalised and interpretable patient survival predictions. The model output includes risk scores, risk groups, estimated survival probability over time, and identifies which genes contribute most significantly to risk predictions. A comprehensive shiny app was also developed to enable ease of use, allowing users to input CSV files and receive a personalised risk assessment.

![Figure 1: Flowchart diagram outlining the entire project pipeline from processing data to predicting survival results](assets/fig1.jpeg)

## 1. Background

Infamous amongst cancers for its commonly late diagnosis and poor survival prognosis, there is a crucial need for improved tools to predict outcomes and support personalised treatment for pancreatic cancer patients. Gene expression profiling has emerged as a promising approach for identifying biomarkers that can help guide clinical decisions for treatment and care (Newhook et al., 2014). However, the dimensionality of gene expression data poses a significant analytical hurdle. The risks include overfitting, a heavy computational load, and difficulty in interpreting the results.

This project aimed to develop a robust survival prediction model using gene expression data from tumorous tissue samples. The goal was to improve patient care by generating interpretable insights for pathologists, clinicians and researchers from high-dimensional gene expression data using machine learning techniques. The resulting Shiny app was specifically designed to provide pathologists with an intuitive and practical tool to support decision-making in cancer prognosis and patient management.

Data for this project was sourced from the Gene Expression Omnibus (GEO), a public repository containing data for various outlets of research. Based on a 2023 study by Posta and Győrffy two datasets were selected, GSE28735, GSE62452, containing 45 and 69 tumour samples respectively. Using the R package GEOquery, the data was loaded, phenotype data cleaned and standardised to unify survival endpoints and filtered to retain tumour samples with complete follow-up. Expression matrices were merged by intersecting genes, yielding a combined dataset of 105 samples and 28,000+genes. A holdout set of four samples was reserved for external validation, while the remaining data was partitioned to ensure robust model training, testing and validation.

The CoxBoost model was chosen for this report due to its ability to handle high dimensional data. CoxBoost is a survival analysis approach that combines componentwise likelihood based boosting with Cox proportional hazards regression. Boosting is an iterative modelling strategy that continuously adds simple models to gradually correct the errors or deficiencies generated in the previous iteration, thereby continuously improving prediction accuracy. Specifically, in each iteration, the direction for the next optimisation is determined based on the deficiencies of the current model. Then, a new model is trained to make up for these deficiencies, ultimately forming an overall model with better comprehensive performance (Simon et al., 2011).

CoxBoost precisely combines this boosting strategy with Cox regression. It can not only handle the right deletion problem in survival data very well, but also deal with the common modelling instability problem in high-dimensional data. Compared with the traditional Cox regression, CoxBoost can maintain good stability and predictive performance even when the number of variables is much greater than the number of samples (Bair et al., 2006).

## 2. Method

This project encompassed multiple stages, beginning with data preprocessing and exploratory data analysis. Subsequently, feature selection was conducted alongside the development and hyperparameter tuning of survival prediction models. Following the construction of a preliminary model, rigorous evaluation was performed using a range of performance metrics. Finally, the refined model was deployed as an interactive Shiny web application, providing a user-friendly platform to demonstrate the final product. All analyses were conducted in R, leveraging a diverse suite of CRAN and Bioconductor packages.

### 2.1 Data Preprocessing

Gene expression and clinical data for the datasets were loaded into the R Studio environment through the GEOquery R package. The datasets contained data on pancreatic cancer samples, including the gene expression values, as well as clinical phenotype information regarding the patients. The first step taken was to align our phenotype data for uniformity across the datasets, Specifically the outcome variables denoted by event status (is_dead) and survival time (months_survived) and non-tumour samples were removed, ensuring that only tumour samples with complete survival status information were retained. This step was important to enable easier merging and consistency of data between the two datasets la

Following standardisation, the cleaned gene expression matrices from both datasets were merged based on shared gene symbol identifiers to create a unified dataset. Expression values were log-transformed and viewed to confirm normalised consistency. Finally, the combined dataset was partitioned into training (60%), validation (20%), and test (20%) sets using stratified sampling to maintain balanced proportions and unbiased model evaluation. This stratified sampling method was used to maintain unbiased model evaluation and validate that the model performed well on new, unseen gene expression profiles from patients.

### 2.2 Exploratory Data Analysis

To better understand the structure of the datasets, summary statistics, including mean, median, and quantiles, were calculated for each gene’s expression data across all samples to visualise the data and identify potential outliers. Principal Component Analysis (PCA) was performed on the transposed expression matrix to visualise clustering of classes, as it helps reduce dimensionality while retaining the linear combination of variables with the highest variance. To further explore and understand the data, a heatmap of the 75 most variable genes was generated, with samples annotated by survival status to investigate patterns that might be associated with survival status outcomes. The output from the heatmap allowed for visual inspection of whether certain genes exhibited differential expression correlating with survival status. 

Additionally, the limma package was used to compare gene expression between deceased and surviving patients. The results were summarised in a volcano plot highlighting the spread of genes based on statistical significance, thereby aiding in the identification of relevant genes for our survival predictions.

### 2.3 Feature Selection

Feature selection was required since gene expression data is often high-dimensional, and these datasets were no exception, with over 30,000 gene expression features, despite relatively few samples. To address this, a minimal-depth random survival forest was employed to identify the most significant genes. Minimal depth measures the depth at which a specific gene is first used within a decision tree split. Genes that congregate closer to the top levels of the tree are seen as more important for predictions. (Seifert, Gundlach, & Szymczak, 2019) The genes were ranked based on their allocated minimal depth scores, and the top 15 genes were selected accordingly. This significantly reduced the feature space, eliminating many noisy features, and hence facilitated a faster and more efficient subsequent modelling process.

### 2.4 CoxBoost Model Development

To optimise model performance, a comprehensive grid search was conducted over two key hyperparameters; penalty and step size. The penalty value affects the regularisation applied to the parameter vector in each boosting step to prevent overfitting and ranged from 0 to 50 in increments of 5. Meanwhile, the the stepsize affects the size of each boosting step after a covariate has been selected and took the values of 0.1, 0.3, 0.5, 0.7 and 1.0.

The final model was selected based on the hyperparameter set that achieved the best performance on the test set and then evaluated on a held-out validation set to assess its generalizability. The performance was assessed using two key survival analysis metrics:

**Integrated Brier Score (IBS)**: The IBS reflects the average squared difference between the predicted survival probability and the actual outcome for each individual over time. Lower values indicate better calibration and accuracy of the survival probability estimates for individual patients.

**Concordance Index (C-index)**: The C-index measures the probability that, when comparing two patients, the model correctly identifies the one with the higher risk of an adverse event. Higher values indicate stronger discriminative power between pairs of patients.

Specifically Integrated Brier Score was minimised whilst choosing a suitably high concordance index.

## 3. Results

### 3.1 Model Performance Metrics

While both metrics provide valuable insights, we placed greater emphasis on the IBS score as it aligned more closely with our project’s goal: to deliver accurate survival probability estimates over time, rather than simply ranking patients relative to each other. This focus on calibration and accuracy was especially relevant for our target users, pathologists, who require precise survival probability estimates to inform patient care. After running the hyperparameter grid search, the penalty value of 15 and stepsize of 0.3 were chosen by hand and found that 7 was the optimal number of boosting steps.

The CoxBoost survival model demonstrated excellent predictive performance in multiple evaluation indicators. The Brier score does not exceed 0.25 at any timepoint with an IBS of 0.144, indicating that the predicted probability of the model aligns closely with the actual outcome and has a high calibration accuracy. Further, It achieved a test set C-index of 0.722 indicating a strong discriminative ability, and offering a valuable tool for precision medicine.

![Figure 2: Time dependent area under the Receiver Operating Characteristic curve](assets/AUCROC)

![Figure 3: Kaplan-Meier survival curves for high and low risk groups with a p-value less than 0.05 indicating significant difference](assets/km_curve)

As shown in the above figure, the time-dependent AUC indicates that the model has a high discriminative ability between high and low risk groups at different follow-up time points. Although it slightly decreases over time, it still remains at an high level overall. The Kaplan-Meier survival curve further verified the effectiveness of the model in stratifying patients' risks, exhibiting a significant difference in survival rate between the high and low-risk groups (p = 0.047). In conclusion, this model has good discriminative ability and practical value in survival prediction and risk assessment, and can provide strong support for individualised clinical treatment.

In the feature importance analysis, genes such as AGRN and PRDM16 have the greatest impact on the model prediction results. Among them, AGRN is associated with a poor prognosis, while PRDM16 shows a protective effect, suggesting its potential biological significance in the survival of patients. Several of the selected genes have also been previously implicated in cancer-related pathways, further supporting the biological interpretability of the model (Wang et al, 2025; He et al, 2020). Genes with 0 coefficients were selected in the random survival forest but ultimately contributed no additional predictive value during boosting, indicating low marginal effect.

![Figure 4: Features selected by minimum depth random forest and their coefficients in the CoxBoost model](assets/feat_imp)

### 3.2 Interactive Prediction with Shiny Application

The developed Shiny application provides a user-friendly interface for deploying the trained CoxBoost model. It allows clinicians or researchers to upload gene expression data for a new patient (in the form of a CSV file with gene ids and expression values) and produces personalised survival predictions. The output includes a quantitative risk score, classification into a high- or low-risk group, an estimated median survival, identification of the key genes contributing to the patient's risk profile and the ability to get the predicted probability of survival at a specific timepoint. This tool translates the complex modelling pipeline into an accessible format for potential research or illustrative clinical use.

## 4. Discussion

### 4.1 Model selection

The ultimate goal of this study was to predict patient survival time using gene expression data. However, two major challenges were encountered during the model selection process. Firstly, the dataset contained nearly 30,000 gene variables, resulting in extremely high dimensionality. Additionally, the survival data were right-censored, meaning that some patients were still alive at the end of the follow-up period, so it was only known that they survived up to a certain point rather than their exact survival time. 

In the context of such high-dimensional and right-censored data, traditional methods such as Principal Component Analysis (PCA) and Penalised Cox, the model initially implemented, can easily lead to overfitting. Furthermore, processing such high-dimensional data could also result in a large computational burden(Salerno & Li, 2022). To address these issues, based on a 2020 study by Spooner et al, the alternative approach of a CoxBoost model deemed most suitable to ensure predictive accuracy and reduce the risk of overfitting the dimensionally complex data.

### 4.1 Limitations

Whilst the model demonstrates promising predictive capabilities, there are several limitations to acknowledge. From a biomedical perspective, retrospective datasets can introduce biases related to patient selection. The combined sample size was also relatively small, limiting the statistical power and running the risk of overfitting despite our validation techniques employed. Furthermore, the datasets might not be reflective of the diverse pancreatic cancer population, restricting the generalisability of our findings. The lack of covariates such as cancer stage, gender and age may mean that our model has not picked up on some crucial survival indicators, limiting its predictive capability.

It is also important to note that the gene expression data used in this study are static snapshots recorded at a point in time, and are unable to capture the dynamic and progressive nature of tumour cells as patients progress through pancreatic cancer. This limitation restricts the model’s ability to adapt to changes in gene expression associated with treatment response or tumour evolution, which are critical factors for prognosis.

Another limitation lies in the quality and completeness of clinical annotations accompanying the gene expression data. Many public datasets, including those used in this study, often lack comprehensive and standardised clinical metadata such as treatment regimens, comorbidities, and long-term follow-up outcomes. This scarcity of detailed contextual information may limit the model’s ability to adjust for confounding factors, thereby affecting the accuracy and clinical relevance of the survival predictions.

### 4.2 Future Work

These limitations can be addressed by future research or studies undertaken. From a clinical standpoint, improving robustness and generalisability of the CoxBoost model and feature selection in larger cohorts is necessary. Complementary data, as well as additional data, such as imaging data of the tumour samples, blood tissue data or clinical variables or covariates like tumour stage and gender, could enhance the predictive framework and more precisely predict despite the complexity of the disease. 

From a data science viewpoint, sophisticated modelling approaches such as ensemble methods, deep learning, time-varying or dynamic survival models may be able to more accurately recreate the fluid and nonlinear interactions present in pancreatic cancer biology. The interpretability of individual predictions could be improved by implementing certain modern AI techniques like SHAP or LIME, which could increase clinician confidence in the predictions made by the model. Better batch effect correction strategies may reduce the technical biases from the integration of data from multiple sources. 

Future improvements to the Shiny application could enhance its usability and analytical capabilities. From an accessibility perspective, an enhanced user interface, including tool tips and guided walkthroughs, could improve usability, particularly for non-technical users. Furthermore, the application could be extended to include more visualisations with the ability to render them dynamically on the user's request, thereby reducing clutter and unwanted information. Finally, a particularly valuable extension would be to enable the simultaneous upload of multiple CSV files to compare expressions and predicted probabilities between individuals or cohorts. This could be done through visualisations such as an overlaid or mirrored radar chart. Overall, these additions would support more interactive exploration and comparative analysis, broadening the application’s clinical and research utility.

## 5. Conclusion

In conclusion, this project developed a reproducible data exploration into survival analysis. It used Random Survival Forest-based feature selection with CoxBoost survival modelling to generate a deployed model based on significant gene expressions for pancreatic cancer. The model demonstrated strong predictive performance in the given independent test data and was deployed as an interactive Shiny application for stakeholders. While limitations relating to data uniformity, sample size, and model assumptions exist, this project provides a solid foundation for future efforts in pancreatic cancer research. This work marks a starting point for further improvements to predictive modelling for cancer and further exploration of the biological importance of the identified gene expressions.

## 6. Appendix

### 6.1 Student Contributions

#### 6.1.1 Dylan Herdan

Dylan was primarily responsible for implementation of the Shiny app. This included server logic (eg CSV uploads and prediction handling) as well as the UI (layout, tab structure, visualisations). He led early data exploration, transitioned from the Penalised Cox to CoxBoost model and implemented feature selection and hyperparameter tuning. Dylan also integrated code from other team members into a cohesive pipeline and helped proofread, edit and include the code for the final report.

#### 6.1.2 Jaijun Zhao

Jiajun contributed to drafting the report, focusing on model evaluation using C-index and cross-validation. He also provided feedback on model selection and summarised model performance in the slides, linking it to the Shiny app. and ensuring a clear transition to the Shiny application demonstration.

#### 6.1.3 Shuhan Chen

Shuhan contributed to the project's analytical depth by performing more extensive Exploratory Data Analysis (EDA), including generating key visualisations like PCA plots and heatmaps. Shuhan was responsible for implementing the data splitting strategy for training and testing sets and calculating the confusion matrix for model performance assessment. Shuhan also played a role in drafting and editing sections of the final report.

#### 6.1.4 Cherry Fan

Cherry contributed to the initial exploratory data analysis (EDA), preparing key insights and visualisations that informed subsequent modelling decisions. She created and refined presentation slides to effectively communicate the project’s findings and methodologies. Additionally, Cherry assisted with the editing and finalisation of the project report, ensuring clarity and cohesion in both technical and narrative elements.

#### 6.1.5 Ashley Wang

Ashley helped to write the draft and edit the report, as well as provide feedback on sections written by other members of the group. She helped to find preliminary datasets that were potential candidates for this project, as well as investigating survival analysis on R. She was also responsible for assisting with the exploratory data analysis, including combining the datasets and performing some basic data collection cleaning, visualisations and interpretations. 

#### 6.1.6 Zhantao Shi

Zhantao was responsible for the survival analysis modelling section of the report. He assisted in training models using R, including the Penalised Cox model, and provided detailed textual explanations for the charts presented in the Shiny app.

### 6.2 Bibliography

University of Utah Health. (2019, March 12). Why is pancreatic cancer so deadly? University of Utah Health.<https://healthcare.utah.edu/healthfeed/2019/03/why-pancreatic-cancer-so-deadly>

Newhook, T. E., Blais, E. M., Lindberg, J. M., Adair, S. J., Xin, W., Lee, J. K., Papin, J. A., Parsons, J. T., & Bauer, T. W. (2014). A thirteen-gene expression signature predicts survival of patients with pancreatic cancer and identifies new genes of interest. PloS one, 9(9), e105631

Stephan Seifert, Sven Gundlach, Silke Szymczak, Surrogate minimal depth as an importance measure for variables in random forests, Bioinformatics, Volume 35, Issue 19, October 2019, Pages 3663–3671, <https://doi.org/10.1093/bioinformatics/btz149>

Simon, N., Friedman, J., Hastie, T., & Tibshirani, R. (2011). Regularization paths for Cox’s proportional Hazards model via Coordinate Descent. Journal of Statistical Software, 39(5). https://doi.org/10.18637/jss.v039.i05

Bair, E., Hastie, T., Paul, D., & Tibshirani, R. (2006). Prediction by supervised principal components. Journal of the American Statistical Association, 101(473), 119–137. <https://doi.org/10.1198/016214505000000628> 

Salerno, S., & Li, Y. (2022). High-Dimensional survival Analysis: methods and applications. Annual Review of Statistics and Its Application, 10(1), 25–49. <https://doi.org/10.1146/annurev-statistics-032921-022127>

Spooner, A., Chen, E., Sowmya, A. et al. A comparison of machine learning methods for survival analysis of high-dimensional clinical data for dementia prediction. Sci Rep 10, 20410 (2020). <https://doi.org/10.1038/s41598-020-77220-w> 

He, Z., Yang, C., He, Y., Gong, B., Yin, C., Feng, J., Chen, L., Tang, J., & Chen, Y. (2020). CAMTA1, a novel antitumor gene, regulates proliferation and the cell cycle in glioma by inhibiting AKT phosphorylation. Cellular Signalling, 79, 109882. <https://doi.org/10.1016/j.cellsig.2020.109882>

Wang, Y., Zheng, S., Gao, H., Wang, Y., Chen, Y., & Han, A. (2025). DNA methylation-induced suppression of PRDM16 in colorectal cancer metastasis through the PPARγ/EMT pathway. Cellular Signalling, 111634. <https://doi.org/10.1016/j.cellsig.2025.111634>

Posta M, Győrffy B. (2023). Analysis of a large cohort of pancreatic cancer transcriptomic profiles to reveal the strongest prognostic factors. Clin Transl Sci. <https://doi.org/10.1111/cts.13563>

### 6.3 Code

```{r global_setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(CoxBoost)
library(dplyr)
library(GEOquery)
library(ggplot2)
library(glmnet)
library(Hmisc)
library(limma)
library(randomForestSRC)
library(pec)
library(pROC)
library(prodlim)
library(RColorBrewer)
library(riskRegression)
library(reshape2)
library(survival)
library(survminer)
library(timeROC)
library(tidyr) 

set.seed(3888)

predictRisk.CoxBoost <- function(object, newdata, times, ...) {
  
  # make sure the covariate order is identical
  X <- as.matrix(newdata[, object$xnames, drop = FALSE])
  
  # linear predictor for the NEW data
  lp <- as.vector(predict(object, newdata = X, type = "lp"))
  
  # grab the baseline cumulative hazard that we stored in the model;
  # build a step function so we can evaluate it at arbitrary 'times'
  H0_step <- stats::stepfun(object$bh_time,
                            c(0, object$bh_hazard))
  
  H0_vec  <- H0_step(times)          # baseline cumul. haz. at all eval times
  
  # matrix:  nrow = n_obs,  ncol = length(times)
  surv_mat <- exp(-outer(exp(lp), H0_vec, "*"))
  
  risk_mat <- 1 - surv_mat           # Score() expects RISKS
  return(risk_mat)
}
```

```{r method_data_preprocessing}
# Extract useful data from GEO object
extract_gse_data <- function(gse) {
  list(
    featureData = fData(gse),
    phenoData = pData(gse),
    eMat = exprs(gse)
  )
}

# Robust GEO downloader
get_geo_data <- function(gse_id, destdir = tempdir(), retries = 5) {
  message(paste("[INFO]: Attempting to load", gse_id))
  for (i in 1:retries) {
    tryCatch({
      gse_list <- getGEO(gse_id, destdir = destdir, GSEMatrix = TRUE, AnnotGPL = FALSE)
      gse <- gse_list[[1]]
      return(gse)
    }, error = function(e) {
      message(paste("[INFO]: Attempt", i, "failed for", gse_id, ":", e$message))
      if (i < retries) Sys.sleep(3) else stop(paste("Failed to download", gse_id))
    })
  }
}

# --- Step 1: Load GEO datasets ---
download_dir <- file.path(getwd(), "GEO_data")
if (!dir.exists(download_dir)) dir.create(download_dir)

GSE28735 <- get_geo_data("GSE28735", destdir = download_dir) %>% extract_gse_data()
GSE62452 <- get_geo_data("GSE62452", destdir = download_dir) %>% extract_gse_data()

# --- Step 2: Clean phenotype data ---

pheno287 <- GSE28735$phenoData %>%
  mutate(
    is_dead = as.numeric(replace(`cancer_death:ch1`, `cancer_death:ch1` == "na", NA)),
    months_survived = as.numeric(replace(`survival_month:ch1`, `survival_month:ch1` == "na", NA))
  ) %>%
  filter(!grepl("non-tumor tissue", source_name_ch1) & !is.na(is_dead))

pheno624 <- GSE62452$phenoData %>%
  mutate(
    is_dead = as.numeric(replace(`survival status:ch1`, `survival status:ch1` %in% c("na","?"), NA)),
    months_survived = as.numeric(replace(`survival months:ch1`, `survival months:ch1` %in% c("na","?"), NA))
  ) %>%
  filter(grepl("Pancreatic tumor", `tissue:ch1`) & !is.na(is_dead))

# Combine phenotype
pheno <- bind_rows(pheno287, pheno624)

# --- Step 3: Combine expression data ---

common_genes <- intersect(rownames(GSE28735$eMat), rownames(GSE62452$eMat))
subset_eMat_GSE28735 <- GSE28735$eMat[common_genes, ]
subset_eMat_GSE62452 <- GSE62452$eMat[common_genes, ]
combined_matrix <- cbind(subset_eMat_GSE28735, subset_eMat_GSE62452)

# --- Step 4: Save validation samples and remove them from training data ---

selected_ids <- c("GSM1527137", "GSM1527230", "GSM711944", "GSM711984")

# Save selected samples to CSV
outdir <- file.path(getwd(), "patient_data")
if (!dir.exists(outdir)) dir.create(outdir)

for (sample_id in selected_ids) {
  expr_df <- data.frame(
    gene_id    = rownames(combined_matrix),
    expression = combined_matrix[, sample_id]
  )
  ph <- pheno[sample_id, ]
  expr_df$is_dead         <- ph$is_dead
  expr_df$months_survived <- ph$months_survived
  
  write.csv(expr_df, file = file.path(outdir, paste0(sample_id,"is_dead_", ph$is_dead, ".csv")),
            row.names = FALSE, quote = FALSE)
}

# Remove validation samples
pheno <- pheno[!rownames(pheno) %in% selected_ids, ]
combined_matrix <- combined_matrix[, colnames(combined_matrix) %in% rownames(pheno)]

# Final check
stopifnot(all(colnames(combined_matrix) == rownames(pheno)))

# Final object
gse <- list(
  featureData = GSE28735$featureData,
  phenoData = pheno,
  eMat = combined_matrix
)
```

```{r method_eda}
# Applying summary function across samples
summary_values_eda <- summary(as.vector(gse$eMat))
summary_per_sample_eda <- as.data.frame(t(apply(gse$eMat, 2, summary)))

# Set SampleID as a column (not using rownames to avoid duplication)
summary_per_sample_eda$SampleID <- rownames(summary_per_sample_eda)
rownames(summary_per_sample_eda) <- NULL  # Remove rownames to prevent duplication

summary_per_sample_eda <- summary_per_sample_eda %>%
  rename(
    Min = "Min.",
    Q1 = "1st Qu.",
    Median = "Median",
    Mean = "Mean",
    Q3 = "3rd Qu.",
    Max = "Max."
  ) %>%
  
  select(SampleID, Min, Q1, Median, Mean, Q3, Max)

summary_long_eda <- summary_per_sample_eda %>%
  pivot_longer(cols = c("Min", "Q1", "Median", "Mean", "Q3", "Max"), names_to = "Statistic", values_to = "Value")

# PCA Setup - using survival status instead of tissue
gse$phenoData$Survival_Status <- factor(
  ifelse(gse$phenoData$is_dead == 0, "Alive", "Deceased"),
  levels = c("Alive", "Deceased")
)

pca_all <- prcomp(t(gse$eMat), scale. = TRUE)

# Heatmap Data Preparation 
var_genes_eda <- apply(gse$eMat, 1, var)
top75_genes_eda <- names(sort(var_genes_eda, decreasing = TRUE)[1:75])
annotation_col_eda <- data.frame(Survival = gse$phenoData$Survival_Status)
rownames(annotation_col_eda) <- rownames(gse$phenoData)

# Prepare data for survival time distribution
prepare_survival_time_data <- function() {
  # Create a dataframe with survival time and status
  survival_data <- data.frame(
    SampleID = rownames(gse$phenoData),
    SurvivalTime = gse$phenoData$months_survived, 
    Status = factor(
      ifelse(gse$phenoData$is_dead == 0, "Alive", "Deceased"),
      levels = c("Alive", "Deceased")
    )
  )
  return(survival_data)
}

# Prepare data for volcano plot - differential expression between alive/deceased
prepare_volcano_data <- function() {
  # Create design matrix
  design <- model.matrix(~gse$phenoData$is_dead)
  colnames(design) <- c("Intercept", "Deceased_vs_Alive")
  
  # Fit linear model
  fit <- limma::lmFit(gse$eMat, design)
  fit <- limma::eBayes(fit)
  
  # Get results
  results <- limma::topTable(fit, coef = "Deceased_vs_Alive", number = Inf)
  
  # Add gene names
  results$GeneID <- rownames(results)
  
  # Flag significant genes (adjust threshold as needed)
  results$Significant <- ifelse(results$adj.P.Val < 0.05, "Yes", "No")
  results$Label <- ifelse(results$Significant == "Yes" & abs(results$logFC) > 1, results$GeneID, "")
  
  return(results)
}

survival_time_data <- prepare_survival_time_data()
volcano_data <- prepare_volcano_data()
```

```{r method_select_features}
# Construct survival object with survival time and event status
surv_obj <- with(gse$phenoData, Surv(as.numeric(months_survived), as.numeric(is_dead)))

# Prepare feature matrix
X <- t(gse$eMat) %>% as.matrix()
train_idx <- createDataPartition(factor(gse$phenoData$is_dead), p = 0.80, list = FALSE)

safe_names <- make.names(colnames(X), unique = TRUE)
colnames(X) <- safe_names
lookup <- data.frame(
  safe = safe_names,              # length 28869
  raw  = rownames(gse$eMat),      # length 28869
  stringsAsFactors = FALSE
)

# Split into training and testing sets
X_train <- X[train_idx, ]
X_test  <- X[-train_idx, ]

# Survival objects for training/testing sets
train_surv <- surv_obj[train_idx]
test_surv <- surv_obj[-train_idx]

# Create dataframes for training and testing
train_df <- data.frame(
  time    = as.numeric(gse$phenoData$months_survived[train_idx]),
  is_dead = as.numeric(gse$phenoData$is_dead[train_idx]),
  as.data.frame(X_train, check.names = FALSE)
)

test_df  <- data.frame(
  time    = as.numeric(gse$phenoData$months_survived[-train_idx]),
  is_dead = as.numeric(gse$phenoData$is_dead[-train_idx]),
  as.data.frame(X_test , check.names = FALSE)
)

# Run Random Survival Forest for feature selection
rsf_model <- rfsrc(Surv(time, is_dead) ~ ., data = train_df, 
                   ntree = 1000, 
                   importance = TRUE)

# Get variable importance by minimal depth
var_imp <- var.select(rsf_model, method = "md", verbose = FALSE)

top_by_md <- var_imp$md.obj$topvars          # may be character(0)

if (length(top_by_md) == 0) {                # fall-back: use VIMP
  vimp_sorted <- sort(rsf_model$importance,
                      decreasing = TRUE,
                      na.last   = TRUE)
  top_by_md <- names(vimp_sorted)
}

n_features_to_select <- 15
selected_features <- top_by_md[1:min(n_features_to_select,
                                     length(top_by_md))]
```

```{r method_build_model}

# Prepare data for CoxBoost with selected features only
X_train_selected <- X_train[, selected_features, drop = FALSE]
X_test_selected <- X_test[, selected_features, drop = FALSE]

# STANDARDIZATION STEP
X_train_selected_std <- scale(X_train_selected)
X_test_selected_std <- scale(X_test_selected, 
                             center = attr(X_train_selected_std, "scaled:center"),
                             scale = attr(X_train_selected_std, "scaled:scale"))

# Set up CoxBoost - note it requires time and status separately
train_time <- train_df$time
train_is_dead <- train_df$is_dead  
test_time <- test_df$time
test_is_dead <- test_df$is_dead    

# hyperparams from hptune.rmd chosen by min ibs score
penalty_val <- 15
stepsize <- 0.3


# Cross validate to find optimal number of boosting steps
cv_res <- cv.CoxBoost(
  time      = train_time,
  status    = train_is_dead,
  x         = X_train_selected_std,
  maxstepno = 100,
  K         = 10,
  penalty   = penalty_val,
  stepsize.factor = stepsize,
  unpen.index = NULL
)

# extract optimal steps
optimal_steps <- cv_res$optimal.step

# Fit final CoxBoost model with the same penalty
coxboost_model <- CoxBoost(
  time      = train_time,
  status    = train_is_dead,
  x         = X_train_selected_std,
  stepno    = optimal_steps,
  stepsize.factor = stepsize,
  penalty   = penalty_val,
  unpen.index = NULL
)

# linear predictor for the training data
lp_train <- as.vector(
  predict(coxboost_model,
          newdata = X_train_selected_std,
          type    = "lp",
          at.step = optimal_steps)   # <- returns a vector
)

# data frame that will be fed to coxph()
df_train <- data.frame(
  time   = train_time,
  status = train_is_dead,
  lp     = lp_train       
)

# "null" Cox model 
coxph_base <- coxph(
  Surv(time, status) ~ offset(lp),   
  data   = df_train,
  method = "breslow"
)

bh <- basehaz(coxph_base, centered = FALSE)

coxboost_model$bh_time   <- bh$time
coxboost_model$bh_hazard <- bh$hazard
coxboost_model$stepno <- optimal_steps

# Predict on test set
risk_scores_test <- as.vector(
  predict(coxboost_model,
          newdata = X_test_selected_std,
          type    = "lp",
          at.step = optimal_steps)
)

# Split test data into high/low risk groups using median cutoff
risk_groups <- ifelse(risk_scores_test > median(risk_scores_test), "High", "Low")
risk_groups <- factor(risk_groups, levels = c("Low", "High"))

# Create actual status for comparison
actual_is_dead <- factor(
  ifelse(test_is_dead == 1, "High", "Low"),
  levels = c("Low", "High")
)

# Calculate C-index
c_index <- rcorr.cens(-risk_scores_test, Surv(test_time, test_is_dead))[1]

# Generate confusion matrix
cm_caret <- confusionMatrix(
  data = risk_groups,
  reference = actual_is_dead,
  positive = "High"
)
```

```{r results_km}
prepare_survival_data <- function() {
  data.frame(
    time = test_time,
    status = test_is_dead,
    risk_group = factor(risk_groups)
  )
}
km_data <- prepare_survival_data()
surv_fit <- survfit(Surv(time, status) ~ risk_group, data = km_data)
surv_diff <- survdiff(Surv(time, status) ~ risk_group, data = km_data)

p_val <- 1 - pchisq(surv_diff$chisq, df = length(surv_diff$n) - 1)
p_text <- ifelse(p_val < 0.001, "p < 0.001", paste("p =", round(p_val, 3)))

ggsurvplot(
  surv_fit, data = km_data,
  pval = p_text, risk.table = FALSE,
  palette = c("#2E9FDF", "#E7B800"),
  xlab = "Time (months)", ylab = "Survival Probability",
  title = "Survival by Predicted Risk Group",
  legend.labs = c("Low Risk", "High Risk"),
  legend.title = "Risk Group",
  ggtheme = theme_bw(), conf.int = TRUE,
  censor.shape = "+", censor.size = 4
)
```

```{r results_time_auc}
# Prepare data for time-dependent AUC plot
prepare_time_auc_data <- function() {
  delta <- ifelse(test_is_dead == 1, 1, 0)
  T <- test_time
  marker <- risk_scores_test
  
  n_event <- sum(delta == 1)
  n_cens <- sum(delta == 0)
  if (n_event == 0 || n_cens == 0) return(NULL)
  
  eval_times2 <- seq(6, floor(max(T)), by = 6)
  eval_times2 <- eval_times2[sapply(eval_times2, function(t)
    any(delta == 1 & T <= t) && any(delta == 0 & T >= t))]
  if (length(eval_times2) < 2) return(NULL)
  
  td <- timeROC::timeROC(T, delta, as.numeric(marker), cause = 1,
                         times = eval_times2, iid = TRUE,
                         weighting = "marginal")
  
  auc_df <- data.frame(
    time = td$times,
    auc = td$AUC,
    se = td$inference$vect_sd_1
  )
  auc_df$lower <- pmax(auc_df$auc - 1.96 * auc_df$se, 0)
  auc_df$upper <- pmin(auc_df$auc + 1.96 * auc_df$se, 1)
  auc_df$eval_times <- eval_times2
  
  return(auc_df)
}

plot_data <- prepare_time_auc_data()

ggplot(plot_data, aes(time, auc)) +
  geom_line(colour = "#2E9FDF", linewidth = 1) +
  geom_ribbon(aes(ymin = lower, ymax = upper), fill = "#2E9FDF", alpha = .2) +
  geom_hline(yintercept = .5, linetype = "dashed", colour = "grey50") +
  coord_cartesian(ylim = c(0, 1)) +
  scale_x_continuous(breaks = plot_data$eval_times) +
  theme_bw() +
  labs(title = "Time-dependent AUC (Test Set)",
       x = "Months Since Diagnosis", y = "AUC")
```

```{r results_brier}
# Helper function to calculate Brier score
calculate_brier_score <- function() {
  # Define evaluation times for Brier score
  eval_times <- seq(6, floor(max(test_time)), by = 6)
  eval_times <- eval_times[sapply(eval_times, function(t)
    any(test_is_dead == 1 & test_time <= t) && any(test_time >= t))]
  
  # Prepare test data for Score function
  test_score_df <- data.frame(
    time    = test_time,
    is_dead = test_is_dead,
    as.data.frame(X_test_selected_std)
  )
  
  # Calculate Brier score with error handling
  score_res <- tryCatch({
    riskRegression::Score(
      object       = list(CoxBoost = coxboost_model),
      formula      = Surv(time, is_dead) ~ 1,
      data         = test_score_df,
      times        = eval_times,
      metrics      = "brier",
      cens.model   = "km",
      split.method = "none",
      summary      = "ibs"
    )
  }, error = function(e) e)
  
  # Process results
  if (inherits(score_res, "error") || length(eval_times) < 2) {
    warning("Brier-score computation failed: ",
            if (inherits(score_res, "error")) score_res$message else "no eval times")
    brier_df  <- NULL
    ibs_value <- NA_real_
  } else {
    brier_df <- score_res$Brier$score[score_res$Brier$score$model == "CoxBoost", c("times", "Brier")]
    names(brier_df) <- c("time", "brier")
    ibs_value <- score_res$Brier$score[model == "CoxBoost" & times == max(times), IBS]
  }
  
  return(list(brier_df = brier_df, ibs_value = ibs_value, eval_times = eval_times))
}

brier_results <- calculate_brier_score()
brier_df <- brier_results$brier_df

ggplot(brier_df, aes(time, brier)) +
  geom_line(colour = "#2E9FDF", linewidth = 1) +
  geom_hline(yintercept = .25, linetype = "dashed", colour = "grey60") +
  coord_cartesian(ylim = c(0, 1)) +
  scale_x_continuous(breaks = brier_df$time) +
  theme_bw() +
  labs(title = "Time-dependent Brier Score (Test Set)",
       x = "Months Since Diagnosis", y = "Brier Score")
```

```{r results_metrics}
cat(
  "IBS: ", brier_results$ibs_value, "\n",
  "C-Index: ", c_index, "\n",
  "Optimal Boosting Steps: ", optimal_steps, "\n"
)
```

```{r results_feature_importance}
extract_gene_symbol <- function(gene_assignment) {
  parts <- strsplit(gene_assignment, " // ")[[1]]
  if (length(parts) >= 2) return(trimws(parts[2])) else return(NA)
}

coefs <- coef(coxboost_model)[selected_features]

coef_df <- data.frame(
  feature = selected_features,
  coefficient = coefs,
  stringsAsFactors = FALSE
) %>%
  mutate(
    original_id = lookup$raw[match(feature, lookup$safe)],
    gene_info = GSE28735$featureData$gene_assignment[match(original_id, rownames(GSE28735$featureData))],
    gene_symbol = sapply(gene_info, extract_gene_symbol, USE.NAMES = FALSE),
    display_name = ifelse(!is.na(gene_symbol), 
                          paste0(gene_symbol, " (", feature, ")"), 
                          feature),
    impact = ifelse(coefficient > 0, "Risk (Worse Survival)", "Protective (Better Survival)"),
    abs_coef = abs(coefficient)
  ) %>%
  arrange(desc(abs_coef))

ggplot(coef_df, aes(x = reorder(display_name, abs_coef), y = coefficient, fill = impact)) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = c("Protective (Better Survival)" = "#2E9FDF", 
                               "Risk (Worse Survival)" = "#E7B800")) +
  coord_flip() +
  labs(
    title = "Feature Importance in CoxBoost Survival Model",
    subtitle = "Top genes ranked by effect size",
    x = "", y = "Coefficient",
    fill = "Impact"
  ) +
  theme_bw() +
  theme(
    legend.position = "bottom",
    axis.text.y = element_text(size = 10),
    plot.title = element_text(size = 16, face = "bold"),
    plot.subtitle = element_text(size = 12)
  )
```
